{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-learning-final-project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asmundur/deeplearning-finalproject/blob/master/deep_learning_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-ZwGhCU_HpsU",
        "colab_type": "code",
        "outputId": "ff381b72-1c2b-436f-b329-fededfe4eb5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os, cv2, csv\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, SpatialDropout1D\n",
        "from keras.optimizers import SGD, rmsprop, Adam, Nadam\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.layers import Conv2D, Flatten, MaxPooling2D, Activation, Dropout, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DKOz-CWJTn5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "9f8b1550-a3d0-41d4-a469-79e319ed285e"
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "filename = \"/content/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "\n",
        "\n",
        "\n",
        "!pip install kaggle\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.1.1)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.2.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VeVidkRl2UGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# if not os.path.exists('./data'):\n",
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json\n",
        "if (not os.path.exists('./train')) and (not os.path.exists('./test')):\n",
        "  !kaggle competitions download -c humpback-whale-identification\n",
        "  !unzip -q train.zip -d train\n",
        "  !unzip -q test.zip -d test\n",
        "  !ls train | wc -l\n",
        "  !ls test | wc -l\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VZOIpdzcQiRU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #!ls -a /root/.kaggle\n",
        "\n",
        "# #!cp /content/.kaggle/kaggle.json /root/.kaggle/kaggle.json\n",
        "# if not os.path.exists('./train'):\n",
        "#   !unzip -q train.zip -d train\n",
        "\n",
        "# !ls train | wc -l\n",
        "\n",
        "# if not os.path.exists('./test'):\n",
        "#   !unzip -q test.zip -d test\n",
        "\n",
        "# !ls test | wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNnACYh8KRgj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ]
    },
    {
      "metadata": {
        "id": "B8iSkEPioXWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f8b99625-c08e-4cd7-8c4e-96eed96ef409"
      },
      "cell_type": "code",
      "source": [
        "def getDictFromCsv(filename):\n",
        "  reader = csv.reader(open(filename, 'r'))\n",
        "  d = {}\n",
        "  for row in reader:\n",
        "    k, v = row\n",
        "    d[k] = v\n",
        "  return d\n",
        "\n",
        "train_image_paths = list()\n",
        "test_image_paths = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(\"train\"):\n",
        "    for file in filenames:\n",
        "        if '.jpg' in file and not file.startswith('.'):\n",
        "              train_image_paths.append(os.path.join(dirpath, file))\n",
        "test_image_paths = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(\"test\"):\n",
        "    for file in filenames:\n",
        "        if '.jpg' in file and not file.startswith('.'):\n",
        "              test_image_paths.append(os.path.join(dirpath, file))\n",
        "\n",
        "trainX  = []\n",
        "testX   = []\n",
        "trainY  = []\n",
        "# testY   = []\n",
        "\n",
        "input_labels = []\n",
        "train_dict = getDictFromCsv('train.csv')\n",
        "# test_dict = getDictFromCsv('test.csv')\n",
        "\n",
        "# count = 0\n",
        "for image_path in train_image_paths:\n",
        "    image = cv2.imread(image_path)\n",
        "    label = train_dict[image_path.split(os.path.sep)[-1]]\n",
        "    trainX.extend(image)\n",
        "    trainY += [label]*len(image)\n",
        "#     print([label]*len(image))\n",
        "#     print(len([label]*len(image)))\n",
        "#     print(label)\n",
        "#     original_imgs.append(image)\n",
        "#     if count < test_breakoff:\n",
        "#       images = preprocess_img(image, sz)\n",
        "#       trainX.extend(images)\n",
        "#       trainY += [label]*len(images)\n",
        "#       print([label]*len(images))\n",
        "#       print(len([label]*len(images)))\n",
        "#     else:\n",
        "#       image = cv2.resize(image, dsize=(sz, sz), interpolation=cv2.INTER_NEAREST)\n",
        "#       testX.append(image)\n",
        "#       testY.append(label)\n",
        "#     count += 1\n",
        "\n",
        "for image_path in test_image_paths:\n",
        "    image = cv2.imread(image_path)\n",
        "#     label = train_dict[image_path.split(os.path.sep)[-1]]\n",
        "    testX.extend(image)\n",
        "\n",
        "# Convert the target categorial labels into binary vectors \n",
        "# (for 2-class, binary classification you should use Keras' \n",
        "#  to_categorical function instead as the scikit-learn's LabelBinarizer)\n",
        "lb = LabelBinarizer()    # ... from scikit\n",
        "trainY = lb.fit_transform(trainY)  # ... from scikit\n",
        "trainX = np.array(trainX)\n",
        "testX = np.array(testX)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a9c4ab517ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# count = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YTp9YIPxXHb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}